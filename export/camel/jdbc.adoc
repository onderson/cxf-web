[[ConfluenceContent]]
[[JDBC-JDBCComponent]]
JDBC Component
~~~~~~~~~~~~~~

The *jdbc* component enables you to access databases through JDBC, where
SQL queries (SELECT) and operations (INSERT, UPDATE, etc) are sent in
the message body. This component uses the standard JDBC API, unlike the
link:sql-component.html[SQL Component] component, which uses
spring-jdbc.

Maven users will need to add the following dependency to their `pom.xml`
for this component:

<dependency> <groupId>org.apache.camel</groupId>
<artifactId>camel-jdbc</artifactId> <version>x.x.x</version> <!-- use
the same version as your Camel core version --> </dependency>

This component can only be used to define producer endpoints, which
means that you cannot use the JDBC component in a `from()` statement.

[[JDBC-URIformat]]
URI format
^^^^^^^^^^

jdbc:dataSourceName[?options]

This component only supports producer endpoints.

You can append query options to the URI in the following format,
`?option=value&option=value&...`

[[JDBC-Options]]
Options
^^^^^^^

confluenceTableSmall

[width="100%",cols="34%,33%,33%",options="header",]
|=======================================================================
|Name |Default Value |Description
|`readSize` |`0` |The default maximum number of rows that can be read by
a polling query. The default value is 0.

|`statement.<xxx>` |`null` |*Camel 2.1:* Sets additional options on the
`java.sql.Statement` that is used behind the scenes to execute the
queries. For instance, `statement.maxRows=10`. For detailed
documentation, see the
http://java.sun.com/j2se/1.5.0/docs/api/java/sql/Statement.html[`java.sql.Statement`
javadoc] documentation.

|`useJDBC4ColumnNameAndLabelSemantics` |`true` |*Camel 2.2:* Sets
whether to use JDBC 4/3 column label/name semantics. You can use this
option to turn it `false` in case you have issues with your JDBC driver
to select data. This only applies when using `SQL SELECT` using aliases
(e.g. `SQL SELECT id as identifier, name as given_name from persons`).

|`resetAutoCommit` |`true` |*Camel 2.9:* If true, Camel will set the
autoCommit on the JDBC connection to be false, commit the change after
executing the statement and reset the autoCommit flag of the connection
at the end. If the JDBC connection does not support resetting the
autoCommit flag, set this to false. +
When used with XA transactions you most likely need to set it to false
so that the transaction manager is in charge of committing this tx.

|`allowNamedParameters` |`true` |*Camel 2.12:* Whether to allow using
named parameters in the queries.

|`prepareStatementStrategy` |  |*Camel 2.12:* Allows to plugin to use a
custom `org.apache.camel.component.jdbc.JdbcPrepareStatementStrategy` to
control preparation of the query and prepared statement.

|`useHeadersAsParameters` |`false` |*Camel 2.12:* Set this option to
`true` to use the `prepareStatementStrategy` with named parameters. This
allows to define queries with named placeholders, and use headers with
the dynamic values for the query placeholders.

|`outputType` |`SelectList` |*Camel 2.12.1:* outputType='SelectList',
for consumer or producer, will output a List of Map. `SelectOne` will
output single Java object in the following way: +
a) If the query has only single column, then that JDBC Column object is
returned. (such as SELECT COUNT( * ) FROM PROJECT will return a Long
object. +
b) If the query has more than one column, then it will return a Map of
that result. +
c) If the outputClass is set, then it will convert the query result into
an Java bean object by calling all the setters that match the column
names. It will assume your class has a default constructor to create
instance with. From *Camel 2.14* onwards then SelectList is also
supported. +
d) If the query resulted in more than one rows, it throws an non-unique
result exception. +
*Camel 2.14.0:* New `StreamList` output type value that streams the
result of the query using an `Iterator<Map<String, Object>>`, it can be
used along with the link:splitter.html[Splitter] EIP.

|`outputClass` |`null` |*Camel 2.12.1:* Specify the full package and
class name to use as conversion when outputType=SelectOne. From *Camel
2.14* onwards then SelectList is also supported.

|`beanRowMapper` |  |*Camel 2.12.1:* To use a custom
`org.apache.camel.component.jdbc.BeanRowMapper` when using
`outputClass`. The default implementation will lower case the row names
and skip underscores, and dashes. For example `"CUST_ID"` is mapped as
`"custId"`.

|`useGetBytesForBlob` |`false` |*Camel 2.16:* To read BLOB columns as
bytes instead of string data. This may be needed for certain databases
such as Oracle where you must read BLOB columns as bytes.
|=======================================================================

[[JDBC-Result]]
Result
^^^^^^

By default the result is returned in the OUT body as an
`ArrayList<HashMap<String, Object>>`. The `List` object contains the
list of rows and the `Map` objects contain each row with the `String`
key as the column name. You can use the option `outputType` to control
the result.

*Note:* This component fetches `ResultSetMetaData` to be able to return
the column name as the key in the `Map`.

[[JDBC-MessageHeaders]]
Message Headers
+++++++++++++++

[width="100%",cols="50%,50%",options="header",]
|=======================================================================
|Header |Description
|`CamelJdbcRowCount` |If the query is a `SELECT`, query the row count is
returned in this OUT header.

|`CamelJdbcUpdateCount` |If the query is an `UPDATE`, query the update
count is returned in this OUT header.

|`CamelGeneratedKeysRows` |*Camel 2.10:* Rows that contains the
generated keys.

|`CamelGeneratedKeysRowCount` |*Camel 2.10:* The number of rows in the
header that contains generated keys.

|`CamelJdbcColumnNames` |*Camel 2.11.1:* The column names from the
ResultSet as a `java.util.Set` type.

|`CamelJdbcParameters` |*Camel 2.12:* A `java.util.Map` which has the
headers to be used if `useHeadersAsParameters` has been enabled.
|=======================================================================

[[JDBC-Generatedkeys]]
Generated keys
^^^^^^^^^^^^^^

*Available as of Camel 2.10*

If you insert data using SQL INSERT, then the RDBMS may support auto
generated keys. You can instruct the link:jdbc.html[JDBC] producer to
return the generated keys in headers. +
To do that set the header `CamelRetrieveGeneratedKeys=true`. Then the
generated keys will be provided as headers with the keys listed in the
table above.

You can see more details in this
https://svn.apache.org/repos/asf/camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/JdbcGeneratedKeysTest.java[unit
test].

Using generated keys does not work with together with named parameters.

[[JDBC-Usingnamedparameters]]
Using named parameters
^^^^^^^^^^^^^^^^^^^^^^

*Available as of Camel 2.12*

In the given route below, we want to get all the projects from the
projects table. Notice the SQL query has 2 named parameters, :?lic and
:?min. +
Camel will then lookup these parameters from the message headers. Notice
in the example above we set two headers with constant value +
for the named parameters:

from("direct:projects") .setHeader("lic", constant("ASF"))
.setHeader("min", constant(123)) .setBody("select * from projects where
license = :?lic and id > :?min order by id")
.to("jdbc:myDataSource?useHeadersAsParameters=true")

You can also store the header values in a `java.util.Map` and store the
map on the headers with the key `CamelJdbcParameters`.

[[JDBC-Samples]]
Samples
^^^^^^^

In the following example, we fetch the rows from the customer table.

First we register our datasource in the Camel registry as
`testdb`:\{snippet:id=register|lang=java|url=camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/AbstractJdbcTestSupport.java}Then
we configure a route that routes to the JDBC component, so the SQL will
be executed. Note how we refer to the `testdb` datasource that was bound
in the previous
step:\{snippet:id=route|lang=java|url=camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/JdbcRouteTest.java}Or
you can create a `DataSource` in Spring like
this:\{snippet:id=example|lang=java|url=camel/trunk/components/camel-jdbc/src/test/resources/org/apache/camel/component/jdbc/camelContext.xml}We
create an endpoint, add the SQL query to the body of the IN message, and
then send the exchange. The result of the query is returned in the OUT
body:\{snippet:id=invoke|lang=java|url=camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/JdbcRouteTest.java}If
you want to work on the rows one by one instead of the entire ResultSet
at once you need to use the link:splitter.html[Splitter] EIP such as:

In Camel 2.13.x or
older\{snippet:id=e1|lang=java|url=camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/JdbcRouteSplitTest.java}In
Camel 2.14.x or newer

from("direct:hello") // here we split the data from the testdb into new
messages one by one // so the mock endpoint will receive a message per
row in the table // the StreamList option allows to stream the result of
the query without creating a List of rows // and notice we also enable
streaming mode on the splitter .to("jdbc:testdb?outputType=StreamList")
.split(body()).streaming() .to("mock:result");

[[JDBC-Sample-Pollingthedatabaseeveryminute]]
 +
Sample - Polling the database every minute
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If we want to poll a database using the JDBC component, we need to
combine it with a polling scheduler such as the link:timer.html[Timer]
or link:quartz.html[Quartz] etc. In the following example, we retrieve
data from the database every 60 seconds:

javafrom("timer://foo?period=60000").setBody(constant("select * from
customer")).to("jdbc:testdb").to("activemq:queue:customers");

[[JDBC-Sample-MoveDataBetweenDataSources]]
Sample - Move Data Between Data Sources +
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A common use case is to query for data, process it and move it to
another data source (ETL operations). In the following example, we
retrieve new customer records from the source table every hour,
filter/transform them and move them to a destination table:

javafrom("timer://MoveNewCustomersEveryHour?period=3600000")
.setBody(constant("select * from customer where create_time >
(sysdate-1/24)")) .to("jdbc:testdb") .split(body()) .process(new
MyCustomerProcessor()) //filter/transform results as needed
.setBody(simple("insert into processed_customer
values('$\{body[ID]}','$\{body[NAME]}')")) .to("jdbc:testdb");

 

link:endpoint-see-also.html[Endpoint See Also]

* link:sql.html[SQL]
